{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f9da58d",
   "metadata": {},
   "source": [
    "# 1.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e1b4b16c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:29:48.484482Z",
     "start_time": "2021-06-04T13:29:48.464496Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy  as np\n",
    "import ntpath\n",
    "import math\n",
    "import pickle\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79365dc",
   "metadata": {},
   "source": [
    "## 1.1 Pre settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d733e23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T12:20:50.978532Z",
     "start_time": "2021-06-04T12:20:50.962574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( HTML( '<style>.container { width:100% !important; }</style>') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004270bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "40b452f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T14:12:52.694389Z",
     "start_time": "2021-06-04T14:12:52.631616Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReconhecimentoFacial :\n",
    "     \n",
    "#     model_dnn_type = \"OPENFACE\"\n",
    "#     svc = None\n",
    "#     image_labels = None \n",
    "    \n",
    "    \n",
    "    def __init__(self, model_name):\n",
    "        \n",
    "        \n",
    "        self.model_dnn_type = model_name\n",
    "        self.detecta_rosto = cv.dnn.readNetFromCaffe('../modelosDNN/deploy.prototxt', '../modelosDNN/res10_300x300_ssd_iter_140000.caffemodel')\n",
    "        self.detecta_rosto.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.detecta_rosto.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "\n",
    "        #extracao keypoint rostos OPENFACE\n",
    "        self.open_face = cv.dnn.readNetFromTorch(\"../modelosDNN/openface/openface.nn4.small2.v1.t7\");\n",
    "        self.open_face.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.open_face.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "\n",
    "        self.face_net = cv.dnn.readNetFromTensorflow(\"../modelosDNN/facenet/facenet_graph_final.pb\");\n",
    "        self.face_net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "        self.face_net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
    "        \n",
    "        model_name = \"../modeloSVM/SVC_model.pkl\"\n",
    "        if os.path.exists(model_name):\n",
    "            with open(model_name, 'rb') as file:  \n",
    "                self.svc = pickle.load(file)\n",
    "        \n",
    "        path_model = \"../modeloSVM/etiquetas.pkl\"\n",
    "        if os.path.exists(path_model):\n",
    "            with open(path_model, 'rb') as file:  \n",
    "                self.image_labels = pickle.load(file)\n",
    "\n",
    "     \n",
    "    def absoluteFilePaths(directory):\n",
    "        for dirpath,_,filenames in os.walk(directory):\n",
    "            for f in filenames:\n",
    "                yield os.path.abspath(os.path.join(dirpath, f))\n",
    "                \n",
    "    def ExtractDatasetData(self, path = \"../imagens\"):\n",
    "        image_labels={}\n",
    "        files=[]\n",
    "        indice_etiqueta_lista = []\n",
    "        for file in absoluteFilePaths(path):\n",
    "            #print(ntpath.basename(file))\n",
    "            files.append(file)\n",
    "            nome_arquivo = ntpath.basename(file)\n",
    "            index_1 = nome_arquivo.find(\"@\")\n",
    "            index_2 = nome_arquivo.find(\"-\")\n",
    "\n",
    "            indice_etiqueta = int(nome_arquivo[:index_1])\n",
    "            indice_etiqueta_lista.append(indice_etiqueta)\n",
    "            label_etiqueta = nome_arquivo[index_1+1:index_2]\n",
    "\n",
    "            if indice_etiqueta not in image_labels :\n",
    "                image_labels[indice_etiqueta] = label_etiqueta\n",
    "\n",
    "        return image_labels,files,indice_etiqueta_lista\n",
    "    \n",
    "   \n",
    "    def FindFaceinImage(self, path_image=\"\", img = None):\n",
    "    #correr o dataset e aplicar o modelo para recuperar as keypoints\n",
    "\n",
    "\n",
    "        if img is None:\n",
    "            img = cv.imread(path_image)\n",
    "            if img is None:\n",
    "                return None\n",
    "\n",
    "\n",
    "        blob = cv.dnn.blobFromImage(img, 1.0,(300,300),(104.0, 177.0, 123.0), False, False)\n",
    "        self.detecta_rosto.setInput(blob)\n",
    "        detections = self.detecta_rosto.forward()\n",
    "\n",
    "        return img, detections\n",
    "\n",
    "        \n",
    "    \n",
    "    def ExtractFaceRectangle(self, img, detections, confidence_threshold=0.5):\n",
    "        # loop over the detections\n",
    "        boxes = []\n",
    "        (h, w) = img.shape[:2]\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            # extract the confidence (i.e., probability) associated with the\n",
    "            # prediction\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            # filter out weak detections by ensuring the `confidence` is\n",
    "            # greater than the minimum confidence\n",
    "            if confidence > confidence_threshold:\n",
    "                # compute the (x, y)-coordinates of the bounding box for the\n",
    "                # object\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                startX = max(0, min(startX, w - 1));\n",
    "                startY = max(0, min(startY, h - 1));\n",
    "                endX = max(0, min(endX, w - 1));\n",
    "                endY = max(0, min(endY, h - 1));\n",
    "\n",
    "                boxes.append([(startX, startY, endX, endY),confidence])\n",
    "\n",
    "        return boxes\n",
    "    \n",
    "    def DrawImageFaceRectangle(self, img, box, confidence, text=None):\n",
    "        # draw the bounding box of the face along with the associated\n",
    "                # probability\n",
    "        img2 = img.copy()\n",
    "        if text is None:\n",
    "            text = \"{:.2f}%\".format(confidence * 100)\n",
    "        else :\n",
    "            text = text + \"  {:.2f}%\".format(confidence * 100)\n",
    "        #(startX, startY, endX, endY) = box[0],box[1],box[2],box[3]\n",
    "        (startX, startY, endX, endY) = box\n",
    "        y = endY +20 \n",
    "        cv.rectangle(img2, (startX, startY), (endX, endY),(0, 255, 0), 1)\n",
    "        cv.putText(img2, text, (startX-20, y),cv.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 0), 2)\n",
    "\n",
    "        return img2;\n",
    "\n",
    "\n",
    "    def TrainSVC(self, x_train, y_train):\n",
    "        self.svc = SVC(kernel = \"rbf\", gamma=0.1, class_weight=\"balanced\", decision_function_shape = \"ovr\")\n",
    "        self.svc.fit(x_train,y_train)\n",
    "\n",
    "        model_name = \"../modeloSVM/SVC_model.pkl\"  \n",
    "\n",
    "        with open(model_name, 'wb') as file:  \n",
    "            pickle.dump(self.svc, file)\n",
    "    \n",
    "    def ExtractFacePoints(self, img):\n",
    "        vec = None\n",
    "        if model_dnn_type ==\"OPENFACE\":\n",
    "\n",
    "            blob_f = cv.dnn.blobFromImage(img, 1.0/255.0,(96,96),(0, 0, 0), True, False)\n",
    "            self.open_face.setInput(blob_f)\n",
    "            vec = self.open_face.forward()\n",
    "            vec = cv.normalize(vec, None,-1, 1, cv.NORM_MINMAX)\n",
    "        elif model_dnn_type ==\"FACENET\":\n",
    "\n",
    "            blob_f = cv.dnn.blobFromImage(img, 1.0/255.0,(160,160),(0, 0, 0), True, False)\n",
    "            self.face_net.setInput(blob_f)\n",
    "            vec = self.face_net.forward()\n",
    "            vec = cv.normalize(vec, None,-1, 1, cv.NORM_MINMAX)\n",
    "        return vec\n",
    "    \n",
    "    \n",
    "    def TrainModelfull(self):\n",
    "\n",
    "        self.image_labels,files,indice_etiqueta_lista = ExtractDatasetData()\n",
    "\n",
    "        indexes_ok=[]\n",
    "        array_keypoints=[]\n",
    "        for i,f in enumerate(files):\n",
    "\n",
    "            img, detections = FindFaceinImage(path_image=f)\n",
    "            if detections is not None:\n",
    "                indexes_ok.append(i)\n",
    "                boxes = ExtractFaceRectangle(img,detections,0.5)\n",
    "                for b in boxes:\n",
    "                    #DrawImageFaceRectangle(img,b[0],b[1],)\n",
    "                    (startX, startY, endX, endY) = b[0]\n",
    "                    points = ExtractFacePoints(img[startY:endY,startX:endX])\n",
    "                    if points is not None:\n",
    "                        array_keypoints.append(points)\n",
    "\n",
    "\n",
    "        [indice_etiqueta_lista[i] for i in indexes_ok]\n",
    "\n",
    "        x_train = np.array([arr.flatten() for arr in array_keypoints])\n",
    "        y_train = np.array(indice_etiqueta_lista)\n",
    "        y_train = y_train.reshape(y_train.shape[0],1).ravel()\n",
    "\n",
    "        TrainSVC(x_train,y_train)\n",
    "        model_name = \"../modeloSVM/etiquetas.pkl\"\n",
    "        with open(model_name, 'wb') as file:  \n",
    "            pickle.dump(self.image_labels, file)\n",
    "\n",
    "        print(\"Train finished\")\n",
    "        \n",
    "        \n",
    "    def PredictFace(self, img):\n",
    "        img, detections = FindFaceinImage(img=img)\n",
    "        if detections is not None:\n",
    "            boxes = ExtractFaceRectangle(img,detections,0.5)\n",
    "            for b in boxes:\n",
    "                (startX, startY, endX, endY) = b[0]\n",
    "                points = ExtractFacePoints(img[startY:endY,startX:endX])\n",
    "                if points is not None:\n",
    "                    id_ = self.svc.predict(points)\n",
    "                    df = self.svc.decision_function(points)\n",
    "                    result = softmax(df)\n",
    "                    etiqueta = image_labels[id_[0]]\n",
    "\n",
    "\n",
    "                    return DrawImageFaceRectangle(img,b[0],np.max(result),etiqueta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ddc6e",
   "metadata": {},
   "source": [
    "## 1.2 Load Models DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2635f9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T12:20:53.640731Z",
     "start_time": "2021-06-04T12:20:53.189207Z"
    }
   },
   "outputs": [],
   "source": [
    "#modelo detecta rostos nas imagens\n",
    "detecta_rosto = cv.dnn.readNetFromCaffe('../modelosDNN/deploy.prototxt', '../modelosDNN/res10_300x300_ssd_iter_140000.caffemodel')\n",
    "detecta_rosto.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "detecta_rosto.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "\n",
    "#extracao keypoint rostos OPENFACE\n",
    "open_face = cv.dnn.readNetFromTorch(\"../modelosDNN/openface/openface.nn4.small2.v1.t7\");\n",
    "open_face.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "open_face.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "\n",
    "face_net = cv.dnn.readNetFromTensorflow(\"../modelosDNN/facenet/facenet_graph_final.pb\");\n",
    "face_net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "face_net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "eb309944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T14:07:52.935144Z",
     "start_time": "2021-06-04T14:07:52.482085Z"
    }
   },
   "outputs": [],
   "source": [
    "r = ReconhecimentoFacial(\"OPENFACE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "dc43e29a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T14:08:11.985111Z",
     "start_time": "2021-06-04T14:08:10.215841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train finished\n"
     ]
    }
   ],
   "source": [
    "r.TrainModelfull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94ae42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78d2aafe",
   "metadata": {},
   "source": [
    "# 2.0 General class funcions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107109ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2166766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921276d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c986aa33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:36:08.713013Z",
     "start_time": "2021-06-04T13:36:08.697004Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dnn_type = \"OPENFACE\"\n",
    "svc = None\n",
    "image_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1f27de41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:36:55.508373Z",
     "start_time": "2021-06-04T13:36:55.500397Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"../modeloSVM/SVC_model.pkl\"\n",
    "if os.path.exists(model_name):\n",
    "    with open(model_name, 'rb') as file:  \n",
    "        svc = pickle.load(file)\n",
    "        \n",
    "path_model = \"../modeloSVM/etiquetas.pkl\"\n",
    "if os.path.exists(path_model):\n",
    "    with open(path_model, 'rb') as file:  \n",
    "        image_labels = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bdbd4024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:13:30.560688Z",
     "start_time": "2021-06-04T13:13:30.549718Z"
    }
   },
   "outputs": [],
   "source": [
    "def absoluteFilePaths(directory):\n",
    "    for dirpath,_,filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            yield os.path.abspath(os.path.join(dirpath, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5eb4e067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:13:31.014502Z",
     "start_time": "2021-06-04T13:13:30.998582Z"
    }
   },
   "outputs": [],
   "source": [
    "def ExtractDatasetData(path = \"../imagens\"):\n",
    "    image_labels={}\n",
    "    files=[]\n",
    "    indice_etiqueta_lista = []\n",
    "    for file in absoluteFilePaths(path):\n",
    "        #print(ntpath.basename(file))\n",
    "        files.append(file)\n",
    "        nome_arquivo = ntpath.basename(file)\n",
    "        index_1 = nome_arquivo.find(\"@\")\n",
    "        index_2 = nome_arquivo.find(\"-\")\n",
    "\n",
    "        indice_etiqueta = int(nome_arquivo[:index_1])\n",
    "        indice_etiqueta_lista.append(indice_etiqueta)\n",
    "        label_etiqueta = nome_arquivo[index_1+1:index_2]\n",
    "    #     print(nome_arquivo)\n",
    "    #     print(indice_etiqueta)\n",
    "    #     print(label_etiqueta)\n",
    "    #     print(\"\\n\")\n",
    "\n",
    "        if indice_etiqueta not in image_labels :\n",
    "            image_labels[indice_etiqueta] = label_etiqueta\n",
    "\n",
    "    return image_labels,files,indice_etiqueta_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bac497ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:13:32.812830Z",
     "start_time": "2021-06-04T13:13:32.803855Z"
    }
   },
   "outputs": [],
   "source": [
    "#correr o dataset e aplicar o modelo para recuperar as keypoints\n",
    "def FindFaceinImage(path_image=\"\", img = None):\n",
    "\n",
    "#file = \"C:\\\\KLEBER\\\\PROJETOS PYTHON\\\\ReconhecimentoFacialTelegram\\\\imagens\\\\1@BOLSONARO-1.jpg\"\n",
    "    if img is None:\n",
    "        img = cv.imread(path_image)\n",
    "        if img is None:\n",
    "            return None\n",
    "    \n",
    "    #cv.imshow(\"OpenCV Image Reading\", img)\n",
    "    #cv.waitKey(0)\n",
    "    #cv.destroyAllWindows()\n",
    "    blob = cv.dnn.blobFromImage(img, 1.0,(300,300),(104.0, 177.0, 123.0), False, False)\n",
    "    detecta_rosto.setInput(blob)\n",
    "    detections = detecta_rosto.forward()\n",
    "    #cv.imshow(\"OpenCV Image Reading\", img)\n",
    "    #cv.waitKey(0)\n",
    "    return img, detections\n",
    "#cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "946a834f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:13:34.678300Z",
     "start_time": "2021-06-04T13:13:34.667328Z"
    }
   },
   "outputs": [],
   "source": [
    "def ExtractFaceRectangle(img, detections, confidence_threshold=0.5):\n",
    "    # loop over the detections\n",
    "    boxes = []\n",
    "    (h, w) = img.shape[:2]\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with the\n",
    "        # prediction\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        # filter out weak detections by ensuring the `confidence` is\n",
    "        # greater than the minimum confidence\n",
    "        if confidence > confidence_threshold:\n",
    "            # compute the (x, y)-coordinates of the bounding box for the\n",
    "            # object\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            startX = max(0, min(startX, w - 1));\n",
    "            startY = max(0, min(startY, h - 1));\n",
    "            endX = max(0, min(endX, w - 1));\n",
    "            endY = max(0, min(endY, h - 1));\n",
    "         \n",
    "            boxes.append([(startX, startY, endX, endY),confidence])\n",
    "\n",
    "    return boxes      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f98a64c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:46:41.893938Z",
     "start_time": "2021-06-04T13:46:41.876985Z"
    }
   },
   "outputs": [],
   "source": [
    "def DrawImageFaceRectangle(img, box, confidence, text=None):\n",
    "    # draw the bounding box of the face along with the associated\n",
    "            # probability\n",
    "    img2 = img.copy()\n",
    "    if text is None:\n",
    "        text = \"{:.2f}%\".format(confidence * 100)\n",
    "    else :\n",
    "        text = text + \"  {:.2f}%\".format(confidence * 100)\n",
    "    #(startX, startY, endX, endY) = box[0],box[1],box[2],box[3]\n",
    "    (startX, startY, endX, endY) = box\n",
    "    y = endY +20 \n",
    "    cv.rectangle(img2, (startX, startY), (endX, endY),(0, 255, 0), 1)\n",
    "    cv.putText(img2, text, (startX-20, y),cv.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 0), 2)\n",
    "    # show the output image\n",
    "#     cv.imshow(\"Output\", img2)\n",
    "#     cv.waitKey(0)\n",
    "#     cv.destroyAllWindows()\n",
    "    return img2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac022a25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:13:39.141065Z",
     "start_time": "2021-06-04T13:13:39.121064Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def TrainSVC(x_train, y_train):\n",
    "    svc = SVC(kernel = \"rbf\", gamma=0.1, class_weight=\"balanced\", decision_function_shape = \"ovr\")\n",
    "    svc.fit(x_train,y_train)\n",
    "    \n",
    "    model_name = \"../modeloSVM/SVC_model.pkl\"  \n",
    "\n",
    "    with open(model_name, 'wb') as file:  \n",
    "        pickle.dump(svc, file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "39983471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:13:41.113733Z",
     "start_time": "2021-06-04T13:13:41.104793Z"
    }
   },
   "outputs": [],
   "source": [
    "def ExtractFacePoints(img):\n",
    "    vec = None\n",
    "    if model_dnn_type ==\"OPENFACE\":\n",
    "    \n",
    "        blob_f = cv.dnn.blobFromImage(img, 1.0/255.0,(96,96),(0, 0, 0), True, False)\n",
    "        open_face.setInput(blob_f)\n",
    "        vec = open_face.forward()\n",
    "\n",
    "\n",
    "        vec = cv.normalize(vec, None,-1, 1, cv.NORM_MINMAX)\n",
    "    elif model_dnn_type ==\"FACENET\":\n",
    "        \n",
    "        blob_f = cv.dnn.blobFromImage(img, 1.0/255.0,(160,160),(0, 0, 0), True, False)\n",
    "        face_net.setInput(blob_f)\n",
    "        vec = face_net.forward()\n",
    "\n",
    "\n",
    "        vec = cv.normalize(vec, None,-1, 1, cv.NORM_MINMAX)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bec3c258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:18:50.110528Z",
     "start_time": "2021-06-04T13:18:50.092038Z"
    }
   },
   "outputs": [],
   "source": [
    "def TrainModelfull():\n",
    "    \n",
    "    image_labels,files,indice_etiqueta_lista = ExtractDatasetData()\n",
    "    \n",
    "    indexes_ok=[]\n",
    "    array_keypoints=[]\n",
    "    for i,f in enumerate(files):\n",
    "\n",
    "        img, detections = FindFaceinImage(path_image=f)\n",
    "        if detections is not None:\n",
    "            indexes_ok.append(i)\n",
    "            boxes = ExtractFaceRectangle(img,detections,0.5)\n",
    "            for b in boxes:\n",
    "                #DrawImageFaceRectangle(img,b[0],b[1],)\n",
    "                (startX, startY, endX, endY) = b[0]\n",
    "                points = ExtractFacePoints(img[startY:endY,startX:endX])\n",
    "                if points is not None:\n",
    "                    array_keypoints.append(points)\n",
    "\n",
    "    #             cv.imshow(\"Output\", img[startY:endY,startX:endX])\n",
    "    #             cv.waitKey(0)\n",
    "    #             cv.destroyAllWindows()\n",
    "        #break\n",
    "\n",
    "\n",
    "    [indice_etiqueta_lista[i] for i in indexes_ok]\n",
    "\n",
    "    x_train = np.array([arr.flatten() for arr in array_keypoints])\n",
    "    y_train = np.array(indice_etiqueta_lista)\n",
    "    y_train = y_train.reshape(y_train.shape[0],1).ravel()\n",
    "\n",
    "    TrainSVC(x_train,y_train)\n",
    "    model_name = \"../modeloSVM/etiquetas.pkl\"\n",
    "    with open(model_name, 'wb') as file:  \n",
    "        pickle.dump(image_labels, file)\n",
    "\n",
    "    print(\"Train finished\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7fc007e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T14:13:02.148437Z",
     "start_time": "2021-06-04T14:13:01.685382Z"
    }
   },
   "outputs": [],
   "source": [
    "r = ReconhecimentoFacial(\"OPENFACE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bf01e911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T14:10:23.670307Z",
     "start_time": "2021-06-04T14:10:23.644379Z"
    }
   },
   "outputs": [],
   "source": [
    "r = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "01934386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T14:06:38.330284Z",
     "start_time": "2021-06-04T14:06:38.318316Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainModelfull() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-7e765111b381>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainModelfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: TrainModelfull() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "r.TrainModelfull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dab64760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T14:13:21.425360Z",
     "start_time": "2021-06-04T14:13:20.120299Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv.imread(\"bolso_teste.jpg\")\n",
    "img2 = r.PredictFace(img)\n",
    "cv.imshow(\"Output\", img2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "be44d46a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:44:46.214023Z",
     "start_time": "2021-06-04T13:44:46.205046Z"
    }
   },
   "outputs": [],
   "source": [
    "    def PredictFace(self, img):\n",
    "        img, detections = self.FindFaceinImage(img=img)\n",
    "        if detections is not None:\n",
    "            boxes = self.ExtractFaceRectangle(img,detections,0.4)\n",
    "            #print(boxes)\n",
    "            for b in boxes:\n",
    "                (startX, startY, endX, endY) = b[0]\n",
    "                points = self.ExtractFacePoints(img[startY:endY,startX:endX])\n",
    "                if points is not None:\n",
    "                    print(\"passou\")\n",
    "                    if not self.svc.probability:\n",
    "                        id_ = self.svc.predict(points)\n",
    "                        df = self.svc.decision_function(points)\n",
    "                        result = np.max(softmax(df))\n",
    "                        etiqueta = self.image_labels[id_[0]]\n",
    "                        \n",
    "                    else:\n",
    "                        id_ = self.svc.classes_[np.argmax(self.svc.predict_proba(points))]\n",
    "                        result = np.max(self.svc.predict_proba(points))\n",
    "                        etiqueta = self.image_labels[id_]\n",
    "                    \n",
    "                    img = self.DrawImageFaceRectangle(img,b[0],result,etiqueta)\n",
    "            return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b311df79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596aa80e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7f155d53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:47:05.423697Z",
     "start_time": "2021-06-04T13:47:05.409696Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-5fd229acd1a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "del(img)\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9988748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad97f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05403b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e177b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a72cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25606c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
